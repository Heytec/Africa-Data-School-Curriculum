{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0eb338",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e365e21",
   "metadata": {},
   "source": [
    "### 1 Introduction to Pandas\n",
    "\n",
    "* What is Pandas?\n",
    "* Why use Pandas?\n",
    "* Installing Pandas\n",
    "\n",
    "### 2 Core Pandas Data Structures\n",
    "\n",
    "* Series\n",
    "* DataFrame\n",
    "\n",
    "### 3 Data Import and Export\n",
    "\n",
    "* Reading data from various file formats (CSV, Excel, JSON, etc.)\n",
    "* Writing data to various file formats\n",
    "\n",
    "### 4 Data Exploration and Analysis\n",
    "* Head, tail\n",
    "* Indexing and slicing data\n",
    "* Descriptive statistics\n",
    "* Sorting data\n",
    "* Filtering data\n",
    "* Grouping and aggregating data\n",
    "\n",
    "### 5 Data Manipulation\n",
    "* Renaming columns and indexes\n",
    "* Handling missing data\n",
    "* Merging, joining, and concatenating DataFrames\n",
    "* Reshaping and pivoting data\n",
    "* Applying functions to data\n",
    "* Column  operations\n",
    "* row operations \n",
    "\n",
    "### 6 Assignment: Getting Started with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59d5fa",
   "metadata": {},
   "source": [
    "## Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af3d65",
   "metadata": {},
   "source": [
    "### What is Pandas?\n",
    "Pandas is an open-source Python library that provides easy-to-use and powerful data structures, as well as data analysis tools. The name \"Pandas\" is derived from the term \"Panel Data,\" which is a term used in statistics and econometrics to describe multi-dimensional structured data sets. It was created by Wes McKinney in 2008 and has since become one of the most popular libraries for data manipulation and analysis in Python.\n",
    "\n",
    "\n",
    "Pandas primarily offers two data structures: Series and DataFrame. A Series is a one-dimensional array-like object that can hold any data type, while a DataFrame is a two-dimensional tabular data structure with labeled axes (rows and columns). These data structures make it easy to manipulate, clean, and analyze data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b6263",
   "metadata": {},
   "source": [
    "### Why use Pandas?\n",
    "\n",
    "Pandas is widely used because it offers several benefits for data analysis, including:\n",
    "\n",
    "* Ease of use: Pandas provides an intuitive and user-friendly interface for working with data, making it accessible to both programmers and non-programmers alike.\n",
    "\n",
    "    \n",
    "    \n",
    "* Flexibility: Pandas can handle data of various formats and types, including CSV, Excel, SQL, JSON, and more. It can work with data ranging from small to large datasets and can perform complex operations with minimal code.\n",
    "\n",
    "    \n",
    "    \n",
    "* Efficiency: Pandas is built on top of NumPy, a powerful numerical computing library in Python, which allows for fast and efficient data manipulation and computation.\n",
    "\n",
    "    \n",
    "    \n",
    "* Compatibility: Pandas integrates well with other Python libraries like Matplotlib and Seaborn for data visualization, and Scikit-learn for machine learning.\n",
    "\n",
    "    \n",
    "    \n",
    "* Rich ecosystem: The Pandas library has a large and active community, which continuously contributes to its development, adding new features and improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0c877",
   "metadata": {},
   "source": [
    "### Installing Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e064c",
   "metadata": {},
   "source": [
    "NB : If you are working with Jupyter Notebook or Google Colab, Pandas  should already be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cd999",
   "metadata": {},
   "source": [
    "To install Pandas, you can use the package manager pip (for Python 2) or pip3 (for Python 3). Open your terminal or command prompt and type the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c64d6a",
   "metadata": {},
   "source": [
    "For those using Anaconda distribution, you can install Pandas using the conda package manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8839c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f2f943",
   "metadata": {},
   "source": [
    "Once the installation is complete, you can verify the installation by importing Pandas in your Python script or Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18316f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266fef4",
   "metadata": {},
   "source": [
    "The pd alias is a convention used by the Pandas community to simplify the usage of Pandas functions and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249a952",
   "metadata": {},
   "source": [
    "## Core Pandas Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5807f",
   "metadata": {},
   "source": [
    "Pandas provides two primary data structures: Series and DataFrame. These data structures are designed to handle a wide variety of data types and formats, making it easy to work with and manipulate data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4aeb66",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "A Series is a one-dimensional, labeled array capable of holding any data type (integers, strings, floats, Python objects, etc.). It has an index that labels each element in the vector. You can think of a Series as similar to a Python list with labels for each element.\n",
    "\n",
    "#### Creating a Series\n",
    "\n",
    "You can create a Series by passing a list of values and, optionally, an index. If you don't provide an index, Pandas will create a default integer index ranging from 0 to the length of the data minus one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a Series with default index\n",
    "data = [4, 7, -5, 3]\n",
    "s1 = pd.Series(data)\n",
    "print(s1)\n",
    "\n",
    "# Creating a Series with a custom index\n",
    "index = ['a', 'b', 'c', 'd']\n",
    "s2 = pd.Series(data, index=index)\n",
    "print(s2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73779d",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). You can think of a DataFrame as a table in a spreadsheet, where data is organized in rows and columns.\n",
    "\n",
    "#### Creating a DataFrame\n",
    "There are multiple ways to create a DataFrame. Some common ways include:\n",
    "\n",
    "* From a Series\n",
    "* Reading data from external sources (CSV, Excel, JSON, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca797b",
   "metadata": {},
   "source": [
    " From a Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s1 = pd.Series([25, 30, 35, 40], name='age')\n",
    "s2 = pd.Series(['New York', 'San Francisco', 'Los Angeles', 'Chicago'], name='city')\n",
    "\n",
    "df = pd.concat([s1, s2], axis=1)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735079e2",
   "metadata": {},
   "source": [
    "Reading data from external sources\n",
    "\n",
    "To read data from external sources, like a CSV file, you can use the pd.read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/listings.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36731114",
   "metadata": {},
   "source": [
    " You can also read data from other formats like Excel, JSON, SQL, etc. by using appropriate Pandas functions such as \n",
    "\n",
    "pd.read_excel(),\n",
    "\n",
    "pd.read_json(), \n",
    " \n",
    "or pd.read_sql()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223270c",
   "metadata": {},
   "source": [
    "# Data Import and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29779edc",
   "metadata": {},
   "source": [
    "Pandas provides several functions to read and write data from and to various file formats, making it easy to work with different data sources and formats.\n",
    "\n",
    "### Reading Data from Various File Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb44e3",
   "metadata": {},
   "source": [
    "#### 1. CSV\n",
    "To read data from a CSV (Comma Separated Values) file, you can use the pd.read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118362bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data/listings.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b018f3",
   "metadata": {},
   "source": [
    "#### 2. Excel\n",
    "To read data from an Excel file, you can use the pd.read_excel() function. You may need to install the openpyxl package to read Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8fe46",
   "metadata": {},
   "source": [
    "#### 3. JSON\n",
    "To read data from a JSON (JavaScript Object Notation) file, you can use the pd.read_json() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'data.json'\n",
    "df = pd.read_json(file_path)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c7da9",
   "metadata": {},
   "source": [
    "#### 4. SQL\n",
    "To read data from an SQL database, you can use the pd.read_sql() or pd.read_sql_query() functions. \n",
    "\n",
    "First, you need to establish a connection to the database using an appropriate Python library such as sqlite3 for SQLite databases or pymysql for MySQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Read data from the database using an SQL query\n",
    "query = \"SELECT * FROM employees\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "print(df)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a1373",
   "metadata": {},
   "source": [
    "### Writing Data to Various File Formats\n",
    "\n",
    "\n",
    "#### 1. CSV\n",
    "To write data to a CSV file, you can use the to_csv() method of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b47159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "file_path = 'data/output_data.csv'\n",
    "df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596aef56",
   "metadata": {},
   "source": [
    "### 2. Excel\n",
    "To write data to an Excel file, you can use the to_excel() method of the DataFrame. You may need to install the openpyxl package to write Excel files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "file_path = 'data/output_data.xlsx'\n",
    "df.to_excel(file_path, index=False, sheet_name='Sheet1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e6413",
   "metadata": {},
   "source": [
    "#### 3. JSON\n",
    "To write data to a JSON file, you can use the to_json() method of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "file_path = 'output_data.json'\n",
    "df.to_json(file_path, orient='records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908116c8",
   "metadata": {},
   "source": [
    "#### 4. SQL\n",
    "To write data to an SQL database , you can use the to_sql() method of the DataFrame. \n",
    "\n",
    "First, you need to establish a connection to the database using an appropriate Python library such as sqlite3 for\n",
    "\n",
    "SQLite databases or \n",
    "\n",
    "pymysql for MySQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Write data to the database\n",
    "table_name = 'employees'\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c836f19",
   "metadata": {},
   "source": [
    "Here's an example with MySQL database using the pymysql library:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae602b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set up the database connection parameters\n",
    "user = 'username'\n",
    "password = 'password'\n",
    "host = 'localhost'\n",
    "database = 'my_database'\n",
    "\n",
    "# Connect to the MySQL database\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{database}\")\n",
    "\n",
    "# Write data to the database\n",
    "table_name = 'employees'\n",
    "df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18634bd1",
   "metadata": {},
   "source": [
    "# Data Exploration and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41b2f0",
   "metadata": {},
   "source": [
    "Pandas provides numerous functions and methods to explore and analyze data, which are essential for understanding the dataset and making informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2756e00d",
   "metadata": {},
   "source": [
    "### Head and Tail\n",
    "Pandas provides head() and tail() methods for quickly previewing the first and last rows of a DataFrame, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n",
    "    'age': [25, 30, 35, 40, 45, 50],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago', 'Miami', 'Boston']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first 3 rows\n",
    "df.head(3)\n",
    "\n",
    "# Display the last 2 rows\n",
    "df.tail(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2e024",
   "metadata": {},
   "source": [
    "### Indexing and Slicing Data\n",
    "\n",
    "Pandas provides several methods to index and slice data in a DataFrame, such as .loc[], .iloc[], and .at[].\n",
    "\n",
    "#### 1. Using .loc[]\n",
    "The .loc[] method allows you to index and slice data by label. You can select rows, columns, or both, using row and column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00bded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data, index=['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Select a single row by index label\n",
    "print(df.loc['A'])\n",
    "\n",
    "# Select multiple rows by index labels\n",
    "print(df.loc[['A', 'C']])\n",
    "\n",
    "# Select a single value using row and column labels\n",
    "print(df.loc['A', 'city'])\n",
    "\n",
    "# Slice rows and select specific columns\n",
    "print(df.loc['A':'C', ['name', 'age']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6612ad",
   "metadata": {},
   "source": [
    "#### 2. Using .iloc[]\n",
    "The .iloc[] method allows you to index and slice data by integer position. You can select rows, columns, or both, using row and column indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59997433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Select a single row by index position\n",
    "print(df.iloc[0])\n",
    "\n",
    "# Select multiple rows by index positions\n",
    "print(df.iloc[[0, 2]])\n",
    "\n",
    "# Select a single value using row and column positions\n",
    "print(df.iloc[0, 2])\n",
    "\n",
    "# Slice rows and select specific columns\n",
    "print(df.iloc[0:3, 0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6887864",
   "metadata": {},
   "source": [
    "#### 3. Using .at[]\n",
    "The .at[] method allows you to access a single value in a DataFrame by row and column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data, index=['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Access a single value using row and column labels\n",
    "print(df.at['A', 'city'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2e775",
   "metadata": {},
   "source": [
    "### Descriptive Statistics\n",
    "Pandas provides several methods to compute descriptive statistics of a DataFrame, such as describe(), mean(), median(), min(), max(), std(), sum(), and count()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'income': [50000, 55000, 60000, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Compute the mean\n",
    "print(df.mean())\n",
    "\n",
    "# Compute the median\n",
    "print(df.median())\n",
    "\n",
    "# Find the minimum and maximum values\n",
    "print(df.min())\n",
    "print(df.max())\n",
    "\n",
    "# Compute the standard deviation\n",
    "print(df.std())\n",
    "\n",
    "# Calculate the sum and count\n",
    "print(df.sum())\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d271d34",
   "metadata": {},
   "source": [
    "### Sorting Data\n",
    "\n",
    "To sort a DataFrame by the values in one or more columns, you can use the sort_values() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd963289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort the DataFrame by the 'age' column in ascending order\n",
    "sorted_df = df.sort_values('age')\n",
    "print(sorted_df)\n",
    "\n",
    "# Sort the DataFrame by the 'city' column in descending order\n",
    "sorted_df = df.sort_values('city', ascending=False)\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a27d24",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "You can filter data in a DataFrame by applying conditions to one or more columns. The result will be a new DataFrame with only the rows that meet the specified conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ebaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'age': [25, 30, 35, 40],\n",
    "    'city': ['New York', 'San Francisco', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where the 'age' is greater than 30\n",
    "filtered_df = df[df['age'] > 30]\n",
    "print(filtered_df)\n",
    "\n",
    "# Filter rows where the 'city' is 'New York' or 'Los Angeles'\n",
    "filtered_df = df[df['city'].isin(['New York', 'Los Angeles'])]\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ebdd5",
   "metadata": {},
   "source": [
    "### Grouping and Aggregating Data\n",
    "To group and aggregate data in a DataFrame, you can use the groupby() method followed by an aggregation function such as sum(), mean(), count(), or max()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82595cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'department': ['HR', 'HR', 'IT', 'IT', 'Sales', 'Sales'],\n",
    "    'employee': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n",
    "    'salary': [50000, 55000, 60000, 62000, 70000, 72000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by the 'department' column and compute the total salary\n",
    "grouped_df = df.groupby('department')['salary'].sum()\n",
    "print(grouped_df)\n",
    "\n",
    "# Group by the 'department' column and compute the average salary\n",
    "grouped_df = df.groupby('department')['salary'].mean()\n",
    "print(grouped_df)\n",
    "\n",
    "# Group by the 'department' column and count the number of employees\n",
    "grouped_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87318aea",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "Pandas provides numerous functions and methods for manipulating data in a DataFrame. These tools help in cleaning, reorganizing, and transforming the dataset to facilitate analysis and visualization.\n",
    "\n",
    "### Renaming Columns and Indexes\n",
    "\n",
    "You can rename columns and indexes in a DataFrame using the rename() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccd7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns={'A': 'Col_A', 'B': 'Col_B', 'C': 'Col_C'})\n",
    "print(df)\n",
    "\n",
    "# Rename indexes\n",
    "df = df.rename(index={'X': 'Row_X', 'Y': 'Row_Y', 'Z': 'Row_Z'})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5c6f2",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "\n",
    "Pandas provides several methods for handling missing data in a DataFrame, such as dropna(), fillna(), and interpolate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'A': [1, np.nan, 3],\n",
    "    'B': [4, 5, np.nan],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_no_na = df.dropna()\n",
    "print(df_no_na)\n",
    "\n",
    "# Fill missing values with a specified value\n",
    "df_filled = df.fillna(0)\n",
    "print(df_filled)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19356802",
   "metadata": {},
   "source": [
    "### Merging, Joining, and Concatenating DataFrames\n",
    "\n",
    "Pandas provides several methods to combine DataFrames, such as concat(), merge(), and join().\n",
    "\n",
    "#### Concatenating DataFrames\n",
    "To concatenate DataFrames, you can use the pd.concat() function. This function stacks DataFrames on top of each other (vertically) or side by side (horizontally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "}\n",
    "data2 = {\n",
    "    'A': [7, 8, 9],\n",
    "    'B': [10, 11, 12]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Concatenate DataFrames vertically (default)\n",
    "df_vertical = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_vertical)\n",
    "\n",
    "# Concatenate DataFrames horizontally\n",
    "df_horizontal = pd.concat([df1, df2], axis=1)\n",
    "print(df_horizontal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a0813",
   "metadata": {},
   "source": [
    "#### Merging DataFrames\n",
    "To merge DataFrames based on a common column, you can use the pd.merge() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = {\n",
    "    'key': ['A', 'B', 'C'],\n",
    "    'value': [1, 2, 3]\n",
    "}\n",
    "data2 = {\n",
    "    'key': ['B', 'C', 'D'],\n",
    "    'value': [4, 5, 6]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge DataFrames on the 'key' column (inner join)\n",
    "df_merged = pd.merge(df1, df2, on='key', suffixes=('_left', '_right'))\n",
    "print(df_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05ba76",
   "metadata": {},
   "source": [
    "#### Joining DataFrames\n",
    "To join DataFrames based on index, you can use the join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f847983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "}\n",
    "data2 = {\n",
    "    'C': [7, 8, 9],\n",
    "    'D': [10, 11, 12]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1, index=['X', 'Y', 'Z'])\n",
    "df2 = pd.DataFrame(data2, index=['Y', 'Z', 'W'])\n",
    "\n",
    "# Join DataFrames using index (left join)\n",
    "df_joined = df1.join(df2, how='left')\n",
    "print(df_joined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239616d6",
   "metadata": {},
   "source": [
    "### Reshaping and Pivoting Data\n",
    "\n",
    "To reshape and pivot data in a DataFrame, you can use the pivot() and melt() functions.\n",
    "\n",
    "#### Pivoting Data\n",
    "\n",
    "\n",
    "The pivot() function is used to reshape a DataFrame from a \"long\" format to a \"wide\" format, where each unique value in a column becomes a new column in the output DataFrame. This function takes three main arguments: index, columns, and values. The index argument specifies the column(s) to use as the index for the output DataFrame, the columns argument specifies the column(s) to use as the new columns in the output DataFrame, and the values argument specifies the column(s) to use as the values in the output DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'date': ['2021-01-01', '2021-01-01', '2021-01-02', '2021-01-02'],\n",
    "    'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "    'temperature': [32, 75, 30, 77],\n",
    "    'humidity': [80, 10, 85, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df_pivoted = df.pivot(index='date', columns='city')\n",
    "print(df_pivoted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86e349",
   "metadata": {},
   "source": [
    "#### Melting Data\n",
    "\n",
    "The melt() function, on the other hand, is used to reshape a DataFrame from a \"wide\" format to a \"long\" format, where multiple columns are \"melted\" into a single column. This function takes several arguments, including id_vars, value_vars, var_name, and value_name. The id_vars argument specifies the column(s) to use as identifier variables, the value_vars argument specifies the column(s) to use as the values to be melted, the var_name argument specifies the name for the new column that will contain the melted column headers, and the value_name argument specifies the name for the new column that will contain the melted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'date': ['2021-01-01', '2021-01-02'],\n",
    "    'New York_temperature': [32, 30],\n",
    "    'New York_humidity': [80, 85],\n",
    "    'Los Angeles_temperature': [75, 77],\n",
    "    'Los Angeles_humidity': [10, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Melt the DataFrame\n",
    "df_melted = pd.melt(df, id_vars='date', var_name='city_and_measure', value_name='value')\n",
    "print(df_melted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c9f5f",
   "metadata": {},
   "source": [
    "### Applying Functions to Data\n",
    "\n",
    "You can apply functions to the data in a DataFrame using the apply() and applymap() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca3d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply a function to each column\n",
    "def column_sum(col):\n",
    "    return col.sum()\n",
    "\n",
    "df_sum = df.apply(column_sum)\n",
    "print(df_sum)\n",
    "\n",
    "# Apply a function to each element\n",
    "def double(x):\n",
    "    return x * 2\n",
    "\n",
    "df_doubled = df.applymap(double)\n",
    "print(df_doubled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b772f8",
   "metadata": {},
   "source": [
    "### Column  Operations\n",
    "You can perform various operations on columns and indexes in a DataFrame, such as adding, deleting, and reordering columns or changing the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a new column\n",
    "df['D'] = [10, 11, 12]\n",
    "print(df)\n",
    "\n",
    "# Delete a column\n",
    "df = df.drop('D', axis=1)\n",
    "print(df)\n",
    "\n",
    "# Reorder columns\n",
    "df = df[['C', 'A', 'B']]\n",
    "print(df)\n",
    "\n",
    "# Update a column\n",
    "df['A'] = [10, 20, 30]\n",
    "print(df)\n",
    "\n",
    "# Reset index\n",
    "df_reset = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e94696",
   "metadata": {},
   "source": [
    "###  Row  Operations\n",
    "To add a new row to a DataFrame, you can use the append() method with a dictionary of values or another DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2],\n",
    "    'B': [3, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a new row using a dictionary\n",
    "new_row = {'A': 5, 'B': 6}\n",
    "df = df.append(new_row, ignore_index=True)\n",
    "print(df)\n",
    "\n",
    "# Add a new row using another DataFrame\n",
    "new_row_df = pd.DataFrame({'A': [7], 'B': [8]})\n",
    "df = df.append(new_row_df, ignore_index=True)\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Update a row using .loc[]\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.loc[1] = [20, 50]\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "# Delete a row\n",
    "df = df.drop(1, axis=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060da11",
   "metadata": {},
   "source": [
    "# Assignment: Getting Started with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4268e",
   "metadata": {},
   "source": [
    "In this assignment, you will practice using the Pandas library by performing some basic operations on a given dataset. You will explore the dataset, clean and manipulate the data, and answer some questions based on the data.\n",
    "\n",
    "### Dataset \n",
    "\n",
    "The dataset you will be working with is a collection of information about various video games and their sales. which can be found here. https://www.kaggle.com/datasets/gregorut/videogamesales\n",
    "\n",
    "### Instructions\n",
    "* 1 Import the necessary libraries and load the dataset.\n",
    "* 2 Display the first 10 rows of the dataset.\n",
    "* 3 Display the shape and basic information about the dataset.\n",
    "* 4 Check for missing data and handle it appropriately.\n",
    "* 5 Display the top 5 video games by global sale\n",
    "* 6 Calculate the total sales in North America for the 'Action' genre.\n",
    "* 7 Find the top 3 publishers by global sales.\n",
    "* 8 Calculate the average sales in Europe for the 'Shooter' genre.\n",
    "* 9 Find the game with the highest sales in Japan in the 'Sports' genre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2732b9d",
   "metadata": {},
   "source": [
    "# SOLUTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Import the necessary libraries and load the dataset.\n",
    "import pandas as pd\n",
    "\n",
    "url = \"data/vgsales.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 2 Display the first 10 rows of the dataset.\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "# 3 Display the shape and basic information about the dataset.\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "\n",
    "# 4 Check for missing data and handle it appropriately.\n",
    "print(df.isna().sum())\n",
    "df = df.dropna()\n",
    "\n",
    "# 5 Display the top 5 video games by global sale\n",
    "\n",
    "df_top5_global = df.nlargest(5, 'Global_Sales')\n",
    "print(df_top5_global)\n",
    "\n",
    "# 6 Calculate the total sales in North America for the 'Action' genre.\n",
    "action_sales_na = df[df['Genre'] == 'Action']['NA_Sales'].sum()\n",
    "print(action_sales_na)\n",
    "\n",
    "# 7 Find the top 3 publishers by global sales.\n",
    "top3_publishers = df.groupby('Publisher')['Global_Sales'].sum().nlargest(3)\n",
    "print(top3_publishers)\n",
    "\n",
    "\n",
    "# 8 Calculate the average sales in Europe for the 'Shooter' genre.\n",
    "shooter_avg_sales_eu = df[df['Genre'] == 'Shooter']['EU_Sales'].mean()\n",
    "print(shooter_avg_sales_eu)\n",
    "\n",
    "\n",
    "# 9 Find the game with the highest sales in Japan in the 'Sports' genre.\n",
    "highest_jp_sports = df[df['Genre'] == 'Sports'].nlargest(1, 'JP_Sales')\n",
    "print(highest_jp_sports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a25729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
